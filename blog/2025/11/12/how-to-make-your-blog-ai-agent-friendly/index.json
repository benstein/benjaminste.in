{
  "title": "How to Make Your Blog AI Agent-Friendly (And Why You Should)",
  "date": "2025-11-12",
  "author": "Benjamin Stein",
  "categories": [
    "ai",
    "web",
    "automation",
    "agents"
  ],
  "excerpt": "I just spent an afternoon making my blog maximally friendly to AI agents. Here's what I did, why it matters, and how you should interact with AI-friendly content.",
  "url": "/blog/2025/11/12/how-to-make-your-blog-ai-agent-friendly/",
  "content": "# How to Make Your Blog AI Agent-Friendly (And Why You Should)\n\nI just spent an afternoon making my blog maximally friendly to AI agents. Not because I'm trying to optimize for some dystopian AI-first future, but because I think we're thinking about this backwards.\n\nThe question isn't \"should websites accommodate AI agents?\" The question is \"why are we still making humans parse HTML when machines could do it for them?\"\n\nLet me explain what I built, and why it matters more than you think.\n\n## What I Did: Three Formats, One Source\n\nEvery blog post on this site is now available in three formats:\n\n1. **HTML** - The human-readable version you're reading now\n2. **JSON** - Structured data with full metadata\n3. **Markdown** - Clean text without formatting cruft\n\nTry it yourself. This post exists at:\n- `https://benjaminste.in/blog/2025/11/12/how-to-make-your-blog-ai-agent-friendly/` (HTML)\n- `https://benjaminste.in/blog/2025/11/12/how-to-make-your-blog-ai-agent-friendly/index.json` (JSON)\n- `https://benjaminste.in/blog/2025/11/12/how-to-make-your-blog-ai-agent-friendly/index.md` (Markdown)\n\nThe JSON version includes everything an AI agent needs:\n\n```json\n{\n  \"title\": \"How to Make Your Blog AI Agent-Friendly\",\n  \"date\": \"2025-11-12\",\n  \"author\": \"Benjamin Stein\",\n  \"categories\": [\"ai\", \"web\", \"automation\", \"agents\"],\n  \"excerpt\": \"I just spent an afternoon...\",\n  \"content\": \"Full markdown text...\",\n  \"html_url\": \"https://benjaminste.in/blog/...\",\n  \"json_url\": \"https://benjaminste.in/blog/.../index.json\",\n  \"markdown_url\": \"https://benjaminste.in/blog/.../index.md\"\n}\n```\n\nThe Markdown version is the full post text without any front matter or HTML, optimized for AI consumption while remaining perfectly readable by humans.\n\n## The Technical Implementation\n\nI added several layers of AI-friendly infrastructure:\n\n**1. Alternate Format Links in HTML**\n\nEvery blog post HTML page includes meta tags pointing to the other formats:\n\n```html\n<link rel=\"alternate\" type=\"application/json\"\n      href=\"[...]/index.json\" title=\"JSON version\" />\n<link rel=\"alternate\" type=\"text/markdown\"\n      href=\"[...]/index.md\" title=\"Markdown version\" />\n```\n\nThis is similar to how RSS feeds work - discoverable alternate representations of the same content.\n\n**2. Schema.org Structured Data**\n\nEvery post includes JSON-LD markup so AI agents (and search engines) can understand the content semantically:\n\n```html\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"BlogPosting\",\n  \"headline\": \"...\",\n  \"author\": {\"@type\": \"Person\", \"name\": \"Benjamin Stein\"},\n  \"datePublished\": \"2025-11-12\",\n  \"articleBody\": \"Full post text...\"\n}\n</script>\n```\n\n**3. AI-Friendly robots.txt**\n\nI explicitly allow all major AI crawlers:\n\n```\nUser-agent: GPTBot\nAllow: /\n\nUser-agent: Claude-Web\nAllow: /\n\nUser-agent: CCBot\nAllow: /\n\nAllow: /*.json\nAllow: /*.md\n```\n\nMost sites either block AI crawlers or make them guess. I'm rolling out the welcome mat.\n\n**4. AI Content Manifest**\n\nI created `/ai-content-manifest.json` that describes the site structure, content patterns, and usage policy:\n\n```json\n{\n  \"site\": {\n    \"name\": \"Benjamin Stein's Blog\",\n    \"url\": \"https://benjaminste.in\",\n    \"content_types\": [...]\n  },\n  \"ai_usage_policy\": {\n    \"crawling_allowed\": true,\n    \"training_allowed\": true,\n    \"attribution_requested\": true,\n    \"content_declaration\": \"partial\"\n  }\n}\n```\n\n**5. Human-Readable Documentation**\n\nI added `/AI-README.md` explaining how AI agents should interact with the site, with example curl commands and format specifications.\n\n## Why This Matters (And It's Not What You Think)\n\nThe standard narrative is: \"AI agents are going to consume all web content, so we need to make it machine-readable.\" That's backwards.\n\nThe real story is about improving human access to information.\n\nHere's the thing: I don't use AI agents to read my own blog. But I do use AI agents to research other people's content. When I'm working on a project and need to understand what someone wrote about a topic, I don't want to:\n\n1. Open my browser\n2. Navigate to their site\n3. Scroll through their post\n4. Copy-paste the relevant parts\n5. Switch back to my AI tool\n6. Paste it in\n7. Ask my question\n\nI want to type: \"What does Benjamin Stein say about AI-friendly blogs?\" and have my AI agent fetch the structured data, parse it, and answer my question.\n\n**The AI agent is just a better browser.** It's not replacing human reading; it's making human reading more efficient.\n\n## How You Should Interact With AI-Friendly Content\n\nIf you're building AI agents or using AI tools, here's how to take advantage of AI-friendly sites:\n\n**1. Check for the Manifest**\n\nLook for `/ai-content-manifest.json`. If it exists, it tells you:\n- What content formats are available\n- URL patterns for different content types\n- Usage policies (crawling, training, attribution)\n- Data schemas\n\n**2. Use Alternate Formats**\n\nInstead of scraping HTML, fetch the JSON or Markdown version:\n\n```bash\n# Get structured data\ncurl https://benjaminste.in/blog/2025/11/12/how-to-make-your-blog-ai-agent-friendly/index.json\n\n# Get clean markdown\ncurl https://benjaminste.in/blog/2025/11/12/how-to-make-your-blog-ai-agent-friendly/index.md\n```\n\n**3. Parse the Structured Data**\n\nHTML pages include Schema.org JSON-LD. Parse it directly instead of extracting text from HTML:\n\n```javascript\n// Find the JSON-LD script tag\nconst jsonLd = document.querySelector('script[type=\"application/ld+json\"]');\nconst data = JSON.parse(jsonLd.textContent);\n// Now you have: title, author, date, full article text\n```\n\n**4. Respect the Usage Policy**\n\nThe manifest declares the site's AI usage policy. Mine says:\n- Crawling: ✅ Allowed\n- Training: ✅ Allowed\n- Attribution: Requested\n\nIf a site declares they don't want to be used for training, respect it. The point of machine-readable policies is that machines can read them.\n\n**5. Use the Right Format for the Task**\n\n- **Need metadata?** Fetch the JSON\n- **Need clean text for LLM context?** Fetch the Markdown\n- **Need the full presentation?** Fetch the HTML\n\n## The Broader Point: The Web Should Be For Machines Too\n\nWe've spent 30 years optimizing websites for human eyes. Beautiful typography, responsive layouts, smooth animations. And that's great! But we're now in a world where most web content is initially consumed by machines on behalf of humans.\n\nYour AI assistant reads the web for you. Your research tool scans documentation. Your personal agent monitors sites for updates. These aren't weird edge cases anymore - they're how people actually work.\n\nMaking content AI-friendly isn't about deprioritizing humans. It's about recognizing that machines are now legitimate readers, and they're reading on our behalf.\n\nThe resistance to this is similar to the resistance to RSS feeds in the 2000s. \"Why would people want to read my content outside my beautiful website?\" Because it's more convenient. Because they're using tools that aggregate information. Because access patterns evolve.\n\nAI-friendly content is the RSS of the 2020s.\n\n## What If Everyone Did This?\n\nImagine a web where:\n\n- Every blog post came with clean JSON and Markdown versions\n- Every site published an AI content manifest declaring their policies\n- AI agents could efficiently fetch exactly what they need\n- Humans could use AI tools to research and synthesize information without manual copy-pasting\n\nThis isn't some far-off future. It's a 60-line Ruby script and some meta tags. I did it in an afternoon.\n\nThe hard part isn't the technology. The hard part is the mental model shift: recognizing that optimizing for AI agents optimizes for humans too, because the agents work for us.\n\n## How to Make Your Own Site AI-Friendly\n\nIf you want to do this for your blog, here's the minimal version:\n\n**1. Generate alternate formats**\n\nFor each blog post, create:\n- `post.json` - JSON with title, date, author, content\n- `post.md` - Clean markdown without front matter\n\n**2. Add meta tags**\n\n```html\n<link rel=\"alternate\" type=\"application/json\" href=\"post.json\" />\n<link rel=\"alternate\" type=\"text/markdown\" href=\"post.md\" />\n```\n\n**3. Add Schema.org markup**\n\n```html\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"BlogPosting\",\n  \"headline\": \"Your Title\",\n  \"articleBody\": \"Full text...\"\n}\n</script>\n```\n\n**4. Update robots.txt**\n\n```\nUser-agent: *\nAllow: /\nAllow: /*.json\nAllow: /*.md\n```\n\n**5. Create an AI manifest**\n\nDeclare your policies, content structure, and how agents should interact with your site.\n\nThat's it. You're now AI-agent-friendly.\n\nAll the code for my implementation is [open source on GitHub](https://github.com/benstein/benjaminste.in). The generation script, the manifest format, the meta tag structure - take it all.\n\n## The Future Is Already Here\n\nAI agents aren't coming. They're already here. They're reading your blog posts, analyzing your documentation, researching your portfolio. The question isn't whether to accommodate them - they're already accessing your content through HTML scraping and LLM context windows.\n\nThe question is whether you make it easy or hard.\n\nI choose easy. Because when information is easier for machines to parse, it's easier for humans to use. When content is well-structured, everyone wins - the human readers, the AI agents, and the humans using the AI agents.\n\nThat's not an AI-first web. That's just a better web.\n\n---\n\n*Check out the [AI-README.md](https://benjaminste.in/AI-README.md) and [ai-content-manifest.json](https://benjaminste.in/ai-content-manifest.json) on this site to see the full implementation. Or just curl the JSON version of this post to see it in action.*\n\n*All implementation code is available at [github.com/benstein/benjaminste.in](https://github.com/benstein/benjaminste.in)*",
  "html_url": "https://benjaminste.in/blog/2025/11/12/how-to-make-your-blog-ai-agent-friendly/",
  "json_url": "https://benjaminste.in/blog/2025/11/12/how-to-make-your-blog-ai-agent-friendly/index.json",
  "markdown_url": "https://benjaminste.in/blog/2025/11/12/how-to-make-your-blog-ai-agent-friendly/index.md"
}